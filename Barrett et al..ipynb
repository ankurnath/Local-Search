{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "234fd707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import networkx as nx\n",
    "\n",
    "from src.envs.utils import (\n",
    "                            RandomErdosRenyiGraphGenerator,\n",
    "                            RandomBarabasiAlbertGraphGenerator,\n",
    "                            RandomRegularGraphGenerator,\n",
    "                            RandomCompleteGraphGenerator,\n",
    "                            EdgeType,\n",
    "                            )\n",
    "from scipy.sparse import csr_matrix,save_npz,load_npz\n",
    "from experiments.utils import load_graph_set, mk_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405ab732",
   "metadata": {},
   "source": [
    "# Minimum domninating set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5746619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created dir:  ../data_MDS/validation/BA_200-300\n",
      "created dir:  ../data_MDS/validation/BA_800-1200\n"
     ]
    }
   ],
   "source": [
    "# number_of_vertices = [20,40,60,100,200]\n",
    "number_of_vertices=[(200,300),(800,1200)]\n",
    "distributions = ['BA']\n",
    "number_of_instances=50\n",
    "\n",
    "# for distribution in distributions:\n",
    "for n in number_of_vertices:\n",
    "    folder=f'../data_MDS/validation/BA_{n[0]}-{n[1]}'\n",
    "    mk_dir(folder)\n",
    "\n",
    "    \n",
    "    \n",
    "    # if distribution=='ER':\n",
    "\n",
    "    #     train_graph_generator = RandomErdosRenyiGraphGenerator(n_spins=n,\n",
    "    #                                                             p_connection=0.15,\n",
    "    #                                                             edge_type=EdgeType.DISCRETE)\n",
    "    # else:\n",
    "    #     train_graph_generator = RandomBarabasiAlbertGraphGenerator(n_spins= n,\n",
    "    #                                                                m_insertion_edges=4,\n",
    "    #                                                                edge_type=EdgeType.DISCRETE)\n",
    "\n",
    "    for i in range(number_of_instances):\n",
    "        spin=random.randint(n[0],n[1])\n",
    "        graph=nx.barabasi_albert_graph(n=spin,m=4)\n",
    "        # graph_generator= RandomBarabasiAlbertGraphGenerator(n_spins= random.randint(n[0],n[1]),\n",
    "        #                                                     m_insertion_edges=4,\n",
    "        #                                                     edge_type=EdgeType.UNIFORM)\n",
    "        # graph=graph_generator.get()\n",
    "        graph=nx.to_numpy_array(graph)\n",
    "        save_file_name = f'graph_{str(i).zfill(4)}'\n",
    "        save_file_path=os.path.join(folder,save_file_name)\n",
    "        sparse_matrix = csr_matrix(graph)\n",
    "        \n",
    "        save_npz(save_file_path, sparse_matrix)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db99813",
   "metadata": {},
   "source": [
    "# ER and BA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316c530c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created dir:  data/training/ER_20\n",
      "created dir:  data/training/ER_40\n",
      "created dir:  data/training/ER_60\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m save_file_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder,save_file_name)\n\u001b[1;32m     24\u001b[0m sparse_matrix \u001b[38;5;241m=\u001b[39m csr_matrix(graph)\n\u001b[0;32m---> 26\u001b[0m \u001b[43msave_npz\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse_matrix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/eco_dqn/lib/python3.10/site-packages/scipy/sparse/_matrix_io.py:71\u001b[0m, in \u001b[0;36msave_npz\u001b[0;34m(file, matrix, compressed)\u001b[0m\n\u001b[1;32m     65\u001b[0m arrays_dict\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mmatrix\u001b[38;5;241m.\u001b[39mformat\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     67\u001b[0m     shape\u001b[38;5;241m=\u001b[39mmatrix\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m     68\u001b[0m     data\u001b[38;5;241m=\u001b[39mmatrix\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m     69\u001b[0m )\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compressed:\n\u001b[0;32m---> 71\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavez_compressed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     np\u001b[38;5;241m.\u001b[39msavez(file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39marrays_dict)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msavez_compressed\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/eco_dqn/lib/python3.10/site-packages/numpy/lib/npyio.py:686\u001b[0m, in \u001b[0;36msavez_compressed\u001b[0;34m(file, *args, **kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_savez_compressed_dispatcher)\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavez_compressed\u001b[39m(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    625\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03m    Save several arrays into a single file in compressed ``.npz`` format.\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    684\u001b[0m \n\u001b[1;32m    685\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 686\u001b[0m     \u001b[43m_savez\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/eco_dqn/lib/python3.10/site-packages/numpy/lib/npyio.py:718\u001b[0m, in \u001b[0;36m_savez\u001b[0;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m     val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(val)\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;66;03m# always force zip64, gh-10776\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m zipf\u001b[38;5;241m.\u001b[39mopen(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, force_zip64\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_array(fid, val,\n\u001b[1;32m    720\u001b[0m                            allow_pickle\u001b[38;5;241m=\u001b[39mallow_pickle,\n\u001b[1;32m    721\u001b[0m                            pickle_kwargs\u001b[38;5;241m=\u001b[39mpickle_kwargs)\n\u001b[1;32m    723\u001b[0m zipf\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/eco_dqn/lib/python3.10/zipfile.py:1151\u001b[0m, in \u001b[0;36m_ZipWriteFile.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;66;03m# Flush any data from the compressor, and update header info\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compressor:\n\u001b[0;32m-> 1151\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(buf)\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fileobj\u001b[38;5;241m.\u001b[39mwrite(buf)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "number_of_vertices = [20,40,60,100,200]\n",
    "distributions = ['ER','BA']\n",
    "number_of_instances=4000\n",
    "\n",
    "for distribution in distributions:\n",
    "    for n in number_of_vertices:\n",
    "        folder=f'data/training/{distribution}_{n}'\n",
    "        mk_dir(folder)\n",
    "        \n",
    "        if distribution=='ER':\n",
    "\n",
    "            train_graph_generator = RandomErdosRenyiGraphGenerator(n_spins=n,\n",
    "                                                                    p_connection=0.15,\n",
    "                                                                    edge_type=EdgeType.DISCRETE)\n",
    "        else:\n",
    "            train_graph_generator = RandomBarabasiAlbertGraphGenerator(n_spins= n,\n",
    "                                                                       m_insertion_edges=4,\n",
    "                                                                       edge_type=EdgeType.DISCRETE)\n",
    "\n",
    "        for i in range(number_of_instances):\n",
    "            graph=train_graph_generator.get()\n",
    "            save_file_name = f'{distribution}_{n}vertices_graph_{i}'\n",
    "            save_file_path=os.path.join(folder,save_file_name)\n",
    "            sparse_matrix = csr_matrix(graph)\n",
    "            \n",
    "            save_npz(save_file_path, sparse_matrix)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59e81493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created dir:  ../data/testing/ER_20\n",
      "created dir:  ../data/validation/ER_20\n",
      "100 target graphs loaded from ../_graphs/validation/ER_20spin_p15_100graphs.pkl\n",
      "50 target graphs loaded from ../_graphs/testing/ER_20spin_p15_50graphs.pkl\n",
      "created dir:  ../data/testing/ER_40\n",
      "created dir:  ../data/validation/ER_40\n",
      "100 target graphs loaded from ../_graphs/validation/ER_40spin_p15_100graphs.pkl\n",
      "50 target graphs loaded from ../_graphs/testing/ER_40spin_p15_50graphs.pkl\n",
      "created dir:  ../data/testing/ER_60\n",
      "created dir:  ../data/validation/ER_60\n",
      "100 target graphs loaded from ../_graphs/validation/ER_60spin_p15_100graphs.pkl\n",
      "50 target graphs loaded from ../_graphs/testing/ER_60spin_p15_50graphs.pkl\n",
      "created dir:  ../data/testing/ER_100\n",
      "created dir:  ../data/validation/ER_100\n",
      "100 target graphs loaded from ../_graphs/validation/ER_100spin_p15_100graphs.pkl\n",
      "50 target graphs loaded from ../_graphs/testing/ER_100spin_p15_50graphs.pkl\n",
      "created dir:  ../data/testing/ER_200\n",
      "created dir:  ../data/validation/ER_200\n",
      "100 target graphs loaded from ../_graphs/validation/ER_200spin_p15_100graphs.pkl\n",
      "50 target graphs loaded from ../_graphs/testing/ER_200spin_p15_50graphs.pkl\n",
      "created dir:  ../data/testing/BA_20\n",
      "created dir:  ../data/validation/BA_20\n",
      "100 target graphs loaded from ../_graphs/validation/BA_20spin_m4_100graphs.pkl\n",
      "50 target graphs loaded from ../_graphs/testing/BA_20spin_m4_50graphs.pkl\n",
      "created dir:  ../data/testing/BA_40\n",
      "created dir:  ../data/validation/BA_40\n",
      "100 target graphs loaded from ../_graphs/validation/BA_40spin_m4_100graphs.pkl\n",
      "50 target graphs loaded from ../_graphs/testing/BA_40spin_m4_50graphs.pkl\n",
      "created dir:  ../data/testing/BA_60\n",
      "created dir:  ../data/validation/BA_60\n",
      "100 target graphs loaded from ../_graphs/validation/BA_60spin_m4_100graphs.pkl\n",
      "50 target graphs loaded from ../_graphs/testing/BA_60spin_m4_50graphs.pkl\n",
      "created dir:  ../data/testing/BA_100\n",
      "created dir:  ../data/validation/BA_100\n",
      "100 target graphs loaded from ../_graphs/validation/BA_100spin_m4_100graphs.pkl\n",
      "50 target graphs loaded from ../_graphs/testing/BA_100spin_m4_50graphs.pkl\n",
      "created dir:  ../data/testing/BA_200\n",
      "created dir:  ../data/validation/BA_200\n",
      "100 target graphs loaded from ../_graphs/validation/BA_200spin_m4_100graphs.pkl\n",
      "50 target graphs loaded from ../_graphs/testing/BA_200spin_m4_50graphs.pkl\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "number_of_vertices = [20,40,60,100,200]\n",
    "distributions = ['ER','BA']\n",
    "for distribution in distributions:\n",
    "    for n in number_of_vertices:\n",
    "        test_folder=f'../data/testing/{distribution}_{n}'\n",
    "        val_folder=f'../data/validation/{distribution}_{n}'\n",
    "        shutil.rmtree(test_folder)\n",
    "        shutil.rmtree(val_folder)\n",
    "        # os.rmdir(test_folder)\n",
    "        # os.rmdir(val_folder)\n",
    "        mk_dir(test_folder)\n",
    "        mk_dir(val_folder)\n",
    "        \n",
    "        if distribution=='ER':\n",
    "            val_graph_save_loc=f'../_graphs/testing/ER_{n}spin_p15_50graphs.pkl'\n",
    "            test_graph_save_loc=f'../_graphs/validation/ER_{n}spin_p15_100graphs.pkl'\n",
    "            opt_test=pickle.load(open(f'../_graphs/validation/opts/cuts_ER_{n}spin_p15_100graphs.pkl', 'rb'))\n",
    "        elif distribution=='BA':\n",
    "            val_graph_save_loc=f\"../_graphs/testing/BA_{n}spin_m4_50graphs.pkl\"\n",
    "            test_graph_save_loc=f\"../_graphs/validation/BA_{n}spin_m4_100graphs.pkl\"\n",
    "            opt_test=pickle.load(open(f'../_graphs/validation/opts/cuts_BA_{n}spin_m4_100graphs.pkl', 'rb'))\n",
    "            \n",
    "        graphs_test = load_graph_set(test_graph_save_loc)\n",
    "        graphs_val = load_graph_set(val_graph_save_loc)\n",
    "\n",
    "        test_files=[]\n",
    "        \n",
    "        for i,graph in enumerate(graphs_test):\n",
    "            save_file_name = f'{distribution}_{n}vertices_graph_{str(i).zfill(4)}'\n",
    "            save_file_path=os.path.join(test_folder,save_file_name)\n",
    "            sparse_matrix = csr_matrix(graph)\n",
    "            save_npz(save_file_path, sparse_matrix)\n",
    "            test_files.append(save_file_name)\n",
    "\n",
    "        \n",
    "        opt_file={'Instance':test_files,'OPT':opt_test}\n",
    "        df=pd.DataFrame(opt_file)\n",
    "        df.to_pickle(f'../data/testing/{distribution}_{n}/optimal')\n",
    "\n",
    "        for i,graph in enumerate(graphs_val):\n",
    "            save_file_name = f'{distribution}_{n}vertices_graph_{str(i).zfill(4)}'\n",
    "            save_file_path=os.path.join(val_folder,save_file_name)\n",
    "            sparse_matrix = csr_matrix(graph)\n",
    "            save_npz(save_file_path, sparse_matrix)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22c001a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instance</th>\n",
       "      <th>OPT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BA_200vertices_graph_0000</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BA_200vertices_graph_0001</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BA_200vertices_graph_0002</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BA_200vertices_graph_0003</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BA_200vertices_graph_0004</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BA_200vertices_graph_0095</td>\n",
       "      <td>187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BA_200vertices_graph_0096</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>BA_200vertices_graph_0097</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BA_200vertices_graph_0098</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>BA_200vertices_graph_0099</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Instance    OPT\n",
       "0   BA_200vertices_graph_0000  184.0\n",
       "1   BA_200vertices_graph_0001  192.0\n",
       "2   BA_200vertices_graph_0002  184.0\n",
       "3   BA_200vertices_graph_0003  198.0\n",
       "4   BA_200vertices_graph_0004  194.0\n",
       "..                        ...    ...\n",
       "95  BA_200vertices_graph_0095  187.0\n",
       "96  BA_200vertices_graph_0096  202.0\n",
       "97  BA_200vertices_graph_0097  184.0\n",
       "98  BA_200vertices_graph_0098  194.0\n",
       "99  BA_200vertices_graph_0099  184.0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8602528",
   "metadata": {},
   "source": [
    "# Physics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33190ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created dir:  ../data/training/Physics\n",
      "created dir:  ../data/validation/Physics\n"
     ]
    }
   ],
   "source": [
    "number_of_vertices = [125]\n",
    "\n",
    "number_of_train_instances=4000\n",
    "number_of_val_instances=50\n",
    "\n",
    "distribution='Physics'\n",
    "\n",
    "for n in number_of_vertices:\n",
    "    train_folder=f'../data/training/{distribution}'\n",
    "    val_folder=f'../data/validation/{distribution}'\n",
    "    mk_dir(train_folder)\n",
    "    mk_dir(val_folder)\n",
    "\n",
    "    graph_generator=RandomRegularGraphGenerator(n_spins=n,d=6,edge_type=EdgeType.DISCRETE)\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(number_of_train_instances):\n",
    "        graph=graph_generator.get()\n",
    "        save_file_name = f'{distribution}_{n}vertices_graph_{str(i).zfill(4)}'\n",
    "        save_file_path=os.path.join(train_folder,save_file_name)\n",
    "        sparse_matrix = csr_matrix(graph)\n",
    "        save_npz(save_file_path, sparse_matrix)\n",
    "\n",
    "    for i in range(number_of_val_instances):\n",
    "        graph=graph_generator.get()\n",
    "        save_file_name = f'{distribution}_{n}vertices_graph_{str(i).zfill(4)}'\n",
    "        save_file_path=os.path.join(val_folder,save_file_name)\n",
    "        sparse_matrix = csr_matrix(graph)\n",
    "        save_npz(save_file_path, sparse_matrix)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "379b3b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 target graphs loaded from ../_graphs/benchmarks/ising_125spin_graphs.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "physics_save_loc=f'../_graphs/benchmarks/ising_125spin_graphs.pkl'\n",
    "graphs_test=load_graph_set(physics_save_loc)\n",
    "\n",
    "save_folder='../data/testing/physics'\n",
    "os.makedirs(save_folder,exist_ok=True)\n",
    "\n",
    "instances=[]\n",
    "\n",
    "for i,graph in enumerate(graphs_test):\n",
    "    save_file_name = f'physics_graph_{str(i).zfill(4)}'\n",
    "    save_file_path=os.path.join(save_folder,save_file_name)\n",
    "    sparse_matrix = csr_matrix(graph)\n",
    "    save_npz(save_file_path, sparse_matrix)\n",
    "    instances.append(save_file_name)\n",
    "\n",
    "opt=pickle.load(open(f'../_graphs/benchmarks/opts/cuts_ising_125spin.pkl', 'rb'))\n",
    "\n",
    "opt_file={'Instance':instances,'OPT':opt}\n",
    "df=pd.DataFrame(opt_file)\n",
    "df.to_pickle(f'../data/testing/physics/optimal')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3426a1",
   "metadata": {},
   "source": [
    "# Gflow-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4ba3836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[110.0, 112.0, 106.0, 114.0, 112.0, 110.0, 112.0, 108.0, 110.0, 112.0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_vertices = [125]\n",
    "\n",
    "number_of_train_instances=4000\n",
    "number_of_val_instances=50\n",
    "number_of_test_instances=100\n",
    "\n",
    "distribution='Physics'\n",
    "\n",
    "for n in number_of_vertices:\n",
    "    train_folder=f'../data/training/{distribution}'\n",
    "    val_folder=f'../data/validation/{distribution}'\n",
    "    test_folder=f'../data/testing/{distribution}'\n",
    "    mk_dir(train_folder)\n",
    "    mk_dir(val_folder)\n",
    "\n",
    "    graph_generator=RandomRegularGraphGenerator(n_spins=n,d=6,edge_type=EdgeType.DISCRETE)\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(number_of_train_instances):\n",
    "        graph=graph_generator.get()\n",
    "        save_file_name = f'{distribution}_{n}vertices_graph_{str(i).zfill(4)}'\n",
    "        save_file_path=os.path.join(train_folder,save_file_name)\n",
    "        sparse_matrix = csr_matrix(graph)\n",
    "        save_npz(save_file_path, sparse_matrix)\n",
    "\n",
    "    for i in range(number_of_val_instances):\n",
    "        graph=graph_generator.get()\n",
    "        save_file_name = f'{distribution}_{n}vertices_graph_{str(i).zfill(4)}'\n",
    "        save_file_path=os.path.join(val_folder,save_file_name)\n",
    "        sparse_matrix = csr_matrix(graph)\n",
    "        save_npz(save_file_path, sparse_matrix)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a022c034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instance</th>\n",
       "      <th>OPT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>physics_graph_0000</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>physics_graph_0001</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>physics_graph_0002</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>physics_graph_0003</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>physics_graph_0004</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>physics_graph_0005</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>physics_graph_0006</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>physics_graph_0007</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>physics_graph_0008</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>physics_graph_0009</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Instance    OPT\n",
       "0  physics_graph_0000  110.0\n",
       "1  physics_graph_0001  112.0\n",
       "2  physics_graph_0002  106.0\n",
       "3  physics_graph_0003  114.0\n",
       "4  physics_graph_0004  112.0\n",
       "5  physics_graph_0005  110.0\n",
       "6  physics_graph_0006  112.0\n",
       "7  physics_graph_0007  108.0\n",
       "8  physics_graph_0008  110.0\n",
       "9  physics_graph_0009  112.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55694dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
